---
layout: post
title:  浅谈Eureka设计理念
category: springcloud 
tags: [springcloud]
copyright: springcloud
---

## 浅谈Eureka设计理念

--- 
### 概述
Eureka作为服务注册及发现中心，主要解决如下几个问题：

1. 服务实例如何注册到服务上
> 本质上就是服务启动的时候调用了Eureka Server 的 REST API的register方法。对于Java应用，可以使用Netflix的Eureka Client封装的 API调用。
>对于springcloud的应用，使用spring-cloud-starter-netflix-eureka-client，基于springboot的自动配置，自动实现服务注册

2. 服务实例如何从服务中心剔除
> 正常情况下，服务实例在关闭应用的时候，会通过钩子或其它生命周期回调方法去调用Eureka Serer 的 REST API 的de-register方法，
>来删除自身服务实例信息。另外为了解决服务实例挂掉或异常情况没有及时删除自身信息的问题，Eureka Server 是要求Client端定时进行续约，
>也就是发送心跳，来证明服务实例是存活的、健康的。如果租约超过i顶时间没有进行续约操作，Eureka Server 端会主动剔除。

3. 服务实例信息的一致性问题 
> 服务注册及发现中心不可能是单点的，自身本身就是集群，集群如何保证一致性与Eureka Server的架构有关，下面分AP优于CP、 Peer to Peer架构、
>Zone及Region设计、 SELF PRESERVATION设计 几个方面来阐述

---
### AP 优于 CP
分布式系统领域有个重要的CAP理论。该理论提到了分布式系统的CAP三大特性：
- Consistency：数据一致性，在多副本的情况，数据始终是保持一致的
- Availability：任何时候客户端对集群进行读写操作时，请求能够正常响应，即在一定的延时内完成
- Partition Tolerance：分区容错性，发生通信故障时，整个集群仍然可用

对于分布式系统而言，一般网络条件相对不可控制，出现网络分区也不可避免，因此系统必须具备分区容错性。

对于ZooKeeper,它时"C"P， 它的C并不是严格的强一致性，比如一个客户端A提交写操作，Zookeeper在过半数节点操作成功之后就返回，如果此时
客户端B请求的是未同步的节点，那么就不是A更新的数据。如果在使用的时候需要强一致性，则需要在读取数据的时候先执行sync操作，即与leader节点先同步下数据，
这样才能保证强一致性。在极端情况下发生网络分区，如果leader不在non-quorum分区，那么无法满足Availability特性。

对于Eureka而言，设计者认为，在云端大规模部署的情况下，网络分区是不可避免的，不应该去逃避这个问题，而应该去拥抱它，因此Eureka选择Availability特性。

---
### Peer to Peer 架构
一般来说分布式系统在多个副本之间的复制方式，可分为主从复制和对等复制
1. 主从复制也就是Master-Slave模式，即一个主副本多个从副本，他们之间的数据更新一般分为同步更新、异步更新、同异步混合，该模式在使用的时候一般也用作读写分离
2. 对等复制，是指副本之间不分主从，任何副本都可以接收读写操作，每个副本之间相互进行数据更新，所以它并不会存在写操作压力，但是各个副本之间的数据同步及处理是个
棘手问题。

Eureka Server 采用的就是 Peer to Peer的复制模式

> 客户端

有多个分区的话，会优先选择与应用实例所在分区一样的服务实例，如果没找到则默认使用defaultZone。客户端使用quarantineSet维护了一个不可以用的Eureka Server列表，
请求的时候，优先从可用的列表中信息选择，如果失败则切换到下一个Eureka Server进行重试，重试次数默认为3.

为了防止每个Client端都按照配置文件指定的顺序进行请求造成Eureka Server节点请求分布不均匀的情况，Client端有个定时任务（默认5分钟执行一次）来刷星并随机化Eureka Server的列表。


> 服务端

Eureka Server本身依赖Eureka Client，每个Server是作为其它Server 的Client。在单个Server启动的时候，通过Client请求其它Server节点的一个节点获取注册的应用实例信息，
然后复制到peer节点。为了避免peer节点之间复制死循环，它使用了HEADER_REPLICATION的http header来区分与普通应用实例的请求操作，这样其它peer节点收到请求的时候，就不会对它的peer节点进行复制，从而避免死循环

Eureka Server的P2P 复制模式，针对数据不一致，是通过版本号机制来解决的，在不同副本之间只需要判断请求复制数据的版本号与本地数据的版本号高低就可以。
但是Eureka 没有采用版本号的方式，而是采用了 lastDirtyTimestamp的字段来对比

---
### Zone 及 Region设计
每个Region下面分了多个AvailabilityZone，每个Region之间是隔离的，默认情况下单个Reigon的AvailabilityZone进行复制，不能跨Reigon资源复制

---
### SELF PRESERVATION设计
分布式系统通常都需要对应用实例进行健康检查。为了防止一些网络波动造成的误判，Eureka采用租约的形式

---
**作者：aires的生活日记**  
**出处：[www.aires.net.cn](http://www.aires.net.cn)**   
**版权所有，欢迎保留原文链接进行转载(本内容摘录自重新定义springcloud实战一书)** 

